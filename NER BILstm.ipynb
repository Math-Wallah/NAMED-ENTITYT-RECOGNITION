{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efcfd2e6-56bb-4d93-96cf-e066a517e0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import codecs\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras.layers import Bidirectional, Dense, InputLayer, Embedding, Activation, LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load tagged sentences from your dataset\n",
    "tagged_sentences = codecs.open(\"data.txt\", encoding=\"utf-8\").readlines()\n",
    "\n",
    "# Preprocess your data\n",
    "sentences, sentence_tags = [], []\n",
    "for tagged_sentence in tagged_sentences:\n",
    "    sentence, tags = zip(*ast.literal_eval(tagged_sentence))\n",
    "    sentences.append(np.array(sentence))\n",
    "    sentence_tags.append(np.array(tags))\n",
    "\n",
    "# Split your data into train and test sets\n",
    "(train_sentences, test_sentences, train_tags, test_tags) = train_test_split(sentences, sentence_tags, test_size=0.2)\n",
    "\n",
    "# Define utility functions\n",
    "def get_words(sentences):\n",
    "    words = set([])\n",
    "    for sentence in sentences:\n",
    "        for word in sentence:\n",
    "            words.add(word)\n",
    "    return words\n",
    "\n",
    "def get_tags(sentences_tags):\n",
    "    tags = set([])\n",
    "    for tag in sentences_tags:\n",
    "        for t in tag:\n",
    "            tags.add(t)\n",
    "    return tags\n",
    "\n",
    "# Create vocabulary and tag mappings\n",
    "words = get_words(sentences)\n",
    "tags = get_tags(sentence_tags)\n",
    "\n",
    "word2index = {w: i + 2 for i, w in enumerate(list(words))}\n",
    "word2index['-PAD-'] = 0\n",
    "word2index['-OOV-'] = 1\n",
    "\n",
    "tag2index = {t: i + 1 for i, t in enumerate(list(tags))}\n",
    "tag2index['-PAD-'] = 0\n",
    "\n",
    "# Convert sentences and tags to numerical indices\n",
    "def get_sequences_x(sentences, word2index):\n",
    "    sequences_x = []\n",
    "    for sentence in sentences:\n",
    "        sequence = [word2index.get(word, word2index['-OOV-']) for word in sentence]\n",
    "        sequences_x.append(sequence)\n",
    "    return sequences_x\n",
    "\n",
    "def get_sequences_y(tags, tag2index):\n",
    "    sequences_y = []\n",
    "    for tag in tags:\n",
    "        sequence = [tag2index.get(t, tag2index['-PAD-']) for t in tag]\n",
    "        sequences_y.append(sequence)\n",
    "    return sequences_y\n",
    "\n",
    "train_sentences_x = get_sequences_x(train_sentences, word2index)\n",
    "test_sentences_x = get_sequences_x(test_sentences, word2index)\n",
    "\n",
    "train_tags_y = get_sequences_y(train_tags, tag2index)\n",
    "test_tags_y = get_sequences_y(test_tags, tag2index)\n",
    "\n",
    "# Pad sequences for consistent length\n",
    "MAX_LENGTH = len(max(train_sentences_x, key=len))\n",
    "train_sentences_x = pad_sequences(train_sentences_x, maxlen=MAX_LENGTH, padding='post')\n",
    "test_sentences_x = pad_sequences(test_sentences_x, maxlen=MAX_LENGTH, padding='post')\n",
    "train_tags_y = pad_sequences(train_tags_y, maxlen=MAX_LENGTH, padding='post')\n",
    "test_tags_y = pad_sequences(test_tags_y, maxlen=MAX_LENGTH, padding='post')\n",
    "\n",
    "# Build a custom NER model with a Bidirectional LSTM\n",
    "model = Sequential()\n",
    "model.add(InputLayer(input_shape=(MAX_LENGTH,))\n",
    "model.add(Embedding(len(word2index), 128))\n",
    "model.add(Bidirectional(LSTM(128, return_sequences=True)))\n",
    "model.add(Dense(len(tag2index))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# Define a utility function to convert sequences to categorical data\n",
    "def to_categorical(sequences, categories):\n",
    "    cat_sequences = []\n",
    "    for s in sequences:\n",
    "        cats = []\n",
    "        for item in s:\n",
    "            cat = np.zeros(categories)\n",
    "            cat[item] = 1.0\n",
    "            cats.append(cat)\n",
    "        cat_sequences.append(cats)\n",
    "    return np.array(cat_sequences\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(0.001),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_sentences_x, to_categorical(train_tags_y, len(tag2index)),\n",
    "                    batch_size=32, epochs=10, validation_split=0.2).history\n",
    "\n",
    "# Save the trained model\n",
    "model.save(\"brahui_ner_model.h5\")\n",
    "\n",
    "# Evaluate the model\n",
    "scores = model.evaluate(test_sentences_x, to_categorical(test_tags_y, len(tag2index))\n",
    "print(f\"{model.metrics_names[1]}: {scores[1] * 100}\")  # Accuracy\n",
    "\n",
    "# Use the model for inference\n",
    "# You can use the model for predicting NER tags on new Brahui text data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ca02a2-636a-40ea-b8ab-e687c02406ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import codecs\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Bidirectional, Dense, InputLayer, Embedding, Activation, LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical, pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load tagged sentences from your dataset\n",
    "tagged_sentences = codecs.open(\"data.txt\", encoding=\"utf-8\").readlines()\n",
    "\n",
    "# Preprocess your data\n",
    "sentences, sentence_tags = [], []\n",
    "for tagged_sentence in tagged_sentences:\n",
    "    sentence, tags = zip(*ast.literal_eval(tagged_sentence))\n",
    "    sentences.append(list(sentence))\n",
    "    sentence_tags.append(list(tags))\n",
    "\n",
    "# Split your data into train and test sets\n",
    "(train_sentences, test_sentences, train_tags, test_tags) = train_test_split(sentences, sentence_tags, test_size=0.2)\n",
    "\n",
    "# ... (rest of the code for word2index, tag2index, preprocessing, and model definition)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(0.001),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_sentences_x, to_categorical(train_tags_y, len(tag2index)),\n",
    "                    batch_size=32, epochs=10, validation_split=0.2).history\n",
    "\n",
    "# Save the trained model\n",
    "model.save(\"brahui_ner_model.h5\")\n",
    "\n",
    "# Evaluate the model\n",
    "scores = model.evaluate(test_sentences_x, to_categorical(test_tags_y, len(tag2index))\n",
    "print(f\"{model.metrics_names[1]}: {scores[1] * 100}\")  # Accuracy\n",
    "\n",
    "# Plot accuracy and loss graphs\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history['accuracy'])\n",
    "plt.plot(history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history['loss'])\n",
    "plt.plot(history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
